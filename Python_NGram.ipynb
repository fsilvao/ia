{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZZZpTmIbvmWihrC4pTh1K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fsilvao/ia_public/blob/main/Python_NGram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dha7LcpDmE_F",
        "outputId": "6e9f8205-db33-4588-d50c-b21963c4fd5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigrams más frecuentes: [(('Este', 'es'), 1), (('es', 'un'), 1), (('un', 'ejemplo'), 1), (('ejemplo', 'de'), 1), (('de', 'un'), 1), (('un', 'corpus'), 1), (('corpus', 'para'), 1), (('para', 'la'), 1), (('la', 'demostración'), 1), (('demostración', 'de'), 1), (('de', 'n-grams'), 1), (('n-grams', '.'), 1), (('.', 'Este'), 1), (('Este', 'corpus'), 1), (('corpus', 'es'), 1), (('es', 'pequeño'), 1), (('pequeño', 'pero'), 1), (('pero', 'sirve'), 1), (('sirve', 'para'), 1), (('para', 'ilustrar'), 1), (('ilustrar', 'el'), 1), (('el', 'concepto'), 1), (('concepto', '.'), 1)]\n",
            "Diccionario de bigrams y sus frecuencias: defaultdict(<class 'int'>, {('Este', 'es'): 1, ('es', 'un'): 1, ('un', 'ejemplo'): 1, ('ejemplo', 'de'): 1, ('de', 'un'): 1, ('un', 'corpus'): 1, ('corpus', 'para'): 1, ('para', 'la'): 1, ('la', 'demostración'): 1, ('demostración', 'de'): 1, ('de', 'n-grams'): 1, ('n-grams', '.'): 1, ('.', 'Este'): 1, ('Este', 'corpus'): 1, ('corpus', 'es'): 1, ('es', 'pequeño'): 1, ('pequeño', 'pero'): 1, ('pero', 'sirve'): 1, ('sirve', 'para'): 1, ('para', 'ilustrar'): 1, ('ilustrar', 'el'): 1, ('el', 'concepto'): 1, ('concepto', '.'): 1})\n",
            "La siguiente palabra más probable después de 'Este' es 'es'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Cargar la librería de lenguaje natural\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Importamos las librerías necesarias\n",
        "import random  # Librería para generar números aleatorios\n",
        "import nltk  # Natural Language Toolkit, esencial para procesamiento de lenguaje natural\n",
        "from nltk.util import ngrams  # Función para generar n-grams\n",
        "from nltk import FreqDist  # Función para calcular la frecuencia de distribución\n",
        "from collections import defaultdict  # Diccionario que da un valor predeterminado para claves no existentes\n",
        "import numpy as np  # Librería para operaciones numéricas\n",
        "\n",
        "# Definimos una función para obtener los n-grams más frecuentes de un corpus\n",
        "def obtener_ngrams(corpus, n):\n",
        "    # Tokenizamos el corpus en palabras\n",
        "    tokens = nltk.word_tokenize(corpus)\n",
        "    # Generamos los n-grams a partir de los tokens\n",
        "    n_grams = ngrams(tokens, n)\n",
        "    # Calculamos la frecuencia de cada n-gram\n",
        "    frecuencia = FreqDist(n_grams)\n",
        "    # Devolvemos los n-grams más frecuentes\n",
        "    return frecuencia.most_common()\n",
        "\n",
        "# Creamos un corpus de ejemplo\n",
        "corpus_ejemplo = \"Este es un ejemplo de un corpus para la demostración de n-grams. Este corpus es pequeño pero sirve para ilustrar el concepto.\"\n",
        "\n",
        "# Obtenemos los bigrams más frecuentes del corpus de ejemplo\n",
        "bigrams_frecuentes = obtener_ngrams(corpus_ejemplo, 2)\n",
        "print(\"Bigrams más frecuentes:\", bigrams_frecuentes)\n",
        "\n",
        "# La función anterior tokeniza el texto, genera los n-grams y calcula su frecuencia\n",
        "# Ahora mostramos cómo usar los resultados para algo útil\n",
        "\n",
        "# Creamos un diccionario para almacenar los bigrams y su frecuencia\n",
        "bigrams_dict = defaultdict(int)\n",
        "for bigram, freq in bigrams_frecuentes:\n",
        "    bigrams_dict[bigram] = freq\n",
        "\n",
        "# Mostramos el diccionario de bigrams\n",
        "print(\"Diccionario de bigrams y sus frecuencias:\", bigrams_dict)\n",
        "\n",
        "# Podemos usar los bigrams para predecir la próxima palabra en una secuencia\n",
        "# Definimos una función para predecir la siguiente palabra dada una palabra inicial\n",
        "def predecir_siguiente_palabra(palabra, bigrams_dict):\n",
        "    posibles_siguientes = {bigram[1]: freq for bigram, freq in bigrams_dict.items() if bigram[0] == palabra}\n",
        "    if not posibles_siguientes:\n",
        "        return None\n",
        "    # Elegimos la palabra con mayor frecuencia\n",
        "    siguiente_palabra = max(posibles_siguientes, key=posibles_siguientes.get)\n",
        "    return siguiente_palabra\n",
        "\n",
        "# Probamos la función de predicción\n",
        "palabra_inicial = \"Este\"\n",
        "siguiente_palabra = predecir_siguiente_palabra(palabra_inicial, bigrams_dict)\n",
        "print(f\"La siguiente palabra más probable después de '{palabra_inicial}' es '{siguiente_palabra}'\")\n",
        "\n",
        "# Este es un ejemplo básico de cómo usar n-grams para modelar texto y predecir palabras\n",
        "# En aplicaciones más avanzadas, se puede utilizar un corpus más grande y considerar trigrams o incluso n-grams mayores.\n"
      ]
    }
  ]
}